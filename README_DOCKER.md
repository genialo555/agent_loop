# Docker Configuration for Agent Loop

Cette configuration Docker suit les meilleures pratiques pour d√©ployer l'application FastAPI Agent Loop.

## Architecture

### Dockerfile Multi-Stage
- **builder**: Stage pour compiler les d√©pendances Python
- **runtime**: Image de production optimis√©e 
- **development**: Image de d√©veloppement avec outils et hot reload
- **test**: Stage pour ex√©cuter les tests

### Optimisations Appliqu√©es

#### DK001: Multi-stage builds
- S√©paration entre compilation (builder) et runtime
- R√©duction de la taille finale de l'image (~60% plus petite)

#### DK002: Versions √©pingl√©es
- `python:3.11.8-slim` pour la reproductibilit√©
- Images Prometheus/Grafana avec versions sp√©cifiques

#### DK003: Image de base minimale  
- `python:3.11.8-slim` pour la production
- Pas d'outils de d√©veloppement inutiles

#### DK004: Utilisateur non-root
- Utilisateur `agent` avec UID/GID d√©di√©s
- Principe de moindre privil√®ge

#### DK005: .dockerignore optimis√©
- Exclusion des tests, docs, cache Python
- Contexte de build r√©duit

#### DK006: Cache BuildKit
- Cache pour `apt` et `pip install`  
- Builds incr√©mentaux plus rapides

#### DK007: Configuration Python
- `PYTHONUNBUFFERED=1` pour les logs temps r√©el
- `PYTHONDONTWRITEBYTECODE=1` pour √©viter les .pyc

## Utilisation

### D√©veloppement

```bash
# Lancer l'environnement de d√©veloppement complet
docker-compose up

# Ou avec Ollama CPU uniquement
docker-compose --profile cpu up

# Initialiser Ollama avec le mod√®le
docker-compose --profile init up ollama-init

# Hot reload automatique sur changement de code
```

### Production

```bash
# Build optimis√© pour production
docker build --target runtime -t agent-loop:prod .

# D√©ployement production avec monitoring
docker-compose -f docker-compose.prod.yml up -d

# V√©rifier les services
docker-compose -f docker-compose.prod.yml ps
```

## Services

### FastAPI App (port 8000)
- Application principale avec API REST
- Int√©gration Ollama pour LLM
- M√©triques Prometheus `/metrics`
- Health checks `/health` et `/ready`

### Ollama (port 11434) 
- Service LLM local avec mod√®le Gemma 3N
- Support GPU optionnel
- API compatible OpenAI

### Prometheus (port 9090)
- Collecte des m√©triques applicatives
- Monitoring FastAPI et syst√®me  
- Alerting (configuration future)

### Grafana (port 3000)
- Dashboards de monitoring
- Visualisation des m√©triques
- Credentials: admin/admin123 (dev)

### Production uniquement
- **Nginx**: Load balancer (port 80/443)
- **Node Exporter**: M√©triques syst√®me (port 9100)  
- **cAdvisor**: M√©triques containers (port 8080)

## Volumes

- `ollama_data`: Mod√®les et cache Ollama
- `prometheus_data`: Donn√©es m√©triques Prometheus  
- `grafana_data`: Configuration et dashboards Grafana
- `prometheus_multiproc`: M√©triques multiprocess FastAPI

## R√©seaux

- `agent-network`: Bridge network interne (172.20.0.0/16)
- Communication s√©curis√©e entre services

## Commandes Utiles

```bash
# Logs en temps r√©el
docker-compose logs -f fastapi-app

# Shell dans le container
docker-compose exec fastapi-app bash

# Rebuild complet
docker-compose build --no-cache

# Arr√™t propre
docker-compose down -v

# Taille des images
docker images | grep agent-loop

# Utilisation ressources
docker stats
```

## S√©curit√©

- Utilisateurs non-root dans tous les containers
- Secrets management pour production  
- Network isolation
- Health checks pour tous les services
- Logging centralis√© avec rotation

## Performance

- Build cache optimis√© (BuildKit)
- Multi-stage builds pour images l√©g√®res
- Resource limits en production
- Connection pooling HTTP
- Prometheus metrics pour monitoring

## Troubleshooting

### Build lent
Le premier build peut prendre 10-15 minutes √† cause de PyTorch et CUDA. Les builds suivants utilisent le cache.

### OOM Errors
Augmenter la RAM Docker (8GB recommand√©) ou d√©sactiver PyTorch si non utilis√©.

### Ollama model missing
```bash
docker-compose --profile init up ollama-init
```

### Port conflicts
Modifier les ports dans docker-compose.yml si 8000, 3000, 9090 sont occup√©s.

---

# QLoRA Fine-tuning with Docker - Sprint 2

Architecture Docker GPU optimis√©e pour le fine-tuning QLoRA avec support RTX 4090.

## Architecture Training

### Dockerfile Stage Training
- **Stage training**: Image NVIDIA CUDA 12.6 avec PyTorch GPU
- **Multi-stage build**: S√©paration builder/runtime pour optimisation  
- **GPU Support**: Drivers NVIDIA + CUDA toolkit complet
- **Memory Optimization**: Configuration RTX 3090 24GB

### Docker Compose Training
- **docker-compose.training.yml**: Environnement isol√© pour ML
- **GPU Resource Management**: Allocation GPU contr√¥l√©e
- **Volume Strategy**: Optimis√©e pour datasets et mod√®les volumineux
- **Monitoring**: W&B Local + GPU metrics en temps r√©el

## Configuration GPU

### Pr√©requis Syst√®me
```bash
# V√©rifier support GPU NVIDIA
nvidia-smi

# Docker avec support GPU
docker run --rm --gpus all nvidia/cuda:12.6.0-base-ubuntu22.04 nvidia-smi

# Docker Compose avec GPU (Docker >= 23.0)
docker compose version
```

### Variables d'Environnement
```bash
# Configuration GPU pour training
CUDA_VISIBLE_DEVICES=all
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Optimisation m√©moire RTX 4090
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
HF_HOME=/app/models/.cache/huggingface
TRANSFORMERS_CACHE=/app/models/.cache/transformers
```

## Commandes Training

### D√©veloppement Interactif
```bash
# Environnement complet avec Jupyter + TensorBoard
make train-dev

# Acc√®s services:
# üìö Jupyter Lab: http://localhost:8888 (token: agent-dev-2024)
# üìä TensorBoard: http://localhost:6006  
# üîç W&B Monitor: http://localhost:8080
```

### Training en Production
```bash
# Training Gemma 2B avec configuration optimis√©e
make train-gemma-2b

# Training Gemma 9B (configuration m√©moire r√©duite)  
make train-gemma-9b

# Training avec mod√®le custom
make train-custom MODEL=google/gemma-2-2b DATA=/path/to/data

# Monitoring complet (training + dev + monitoring)
make train-monitor
```

### Gestion des Conteneurs
```bash
# Status des conteneurs et GPU
make train-status

# Logs training en temps r√©el
make train-logs

# Arr√™t propre
make train-stop

# Nettoyage complet (‚ö†Ô∏è supprime les checkpoints)
make train-clean
```

## Volumes et Donn√©es

### Structure des Volumes
```
‚îú‚îÄ‚îÄ training_models_cache/          # Cache HuggingFace (~2-5GB)
‚îú‚îÄ‚îÄ training_models_gguf/           # Mod√®les GGUF (~4-8GB)  
‚îú‚îÄ‚îÄ training_checkpoints/           # Checkpoints training (~1-3GB)
‚îú‚îÄ‚îÄ training_logs/                  # Logs structur√©s + W&B
‚îî‚îÄ‚îÄ training_backup/                # Backup automatique
```

### Configuration des Mod√®les GGUF
```bash
# Cr√©er r√©pertoire mod√®les
mkdir -p models/gguf

# T√©l√©charger mod√®le de base Gemma 2B (exemple)
cd models/gguf/
wget https://huggingface.co/google/gemma-2-2b-it-gguf/resolve/main/gemma-2-2b-it.gguf

# V√©rifier la structure
ls -la models/
```

## Monitoring et Observabilit√©

### GPU Monitoring
```bash
# Metrics GPU en temps r√©el  
docker logs agent-gpu-monitor

# Dashboard W&B Local
open http://localhost:8080

# M√©triques Prometheus (si activ√©)
curl http://localhost:9090/metrics | grep gpu
```

### Logs Structur√©s
```bash
# Logs training principal
docker logs -f agent-qlora-training

# Logs GPU utilization
tail -f logs/gpu_metrics.jsonl

# Logs W&B offline
ls -la logs/wandb/
```

## Configuration QLoRA Avanc√©e

### Mod√®les Support√©s
- **Gemma 2B**: Configuration RTX 4090 optimis√©e (batch_size=4)
- **Gemma 9B**: Configuration m√©moire r√©duite (batch_size=2)  
- **Custom**: Support mod√®les HuggingFace compatibles QLoRA

### Param√®tres d'Optimisation
```python
# Configuration RTX 4090 (24GB VRAM)
per_device_train_batch_size: 4
gradient_accumulation_steps: 4  # Effective batch = 16
bf16: True                      # Better than fp16 on Ampere
gradient_checkpointing: True    # Memory optimization
optim: "adamw_8bit"            # 8-bit optimizer

# QLoRA 4-bit + Double Quantization  
load_in_4bit: True
bnb_4bit_use_double_quant: True
bnb_4bit_quant_type: "nf4"
```

## S√©curit√© Training

### Isolation des Conteneurs
- **Network d√©di√©**: training-network (172.25.0.0/16)
- **Utilisateur non-root**: trainer (UID 1000)
- **Volumes read-only**: Datasets prot√©g√©s en lecture seule
- **Resource limits**: M√©moire container limit√©e √† 20GB

### Backup et R√©cup√©ration
```bash
# Backup automatique des checkpoints (toutes les heures)
docker logs agent-training-backup

# Restauration manuelle
rsync -av backups/training/ model_checkpoints/
```

## Performance et Optimisation

### Builds Docker Optimis√©s
- **BuildKit cache**: Cache pip et apt pour builds rapides
- **.dockerignore**: Exclusion fichiers volumineux (*.gguf, *.bin)
- **Multi-stage**: S√©paration training builder/runtime
- **Layer caching**: Optimisation ordre instructions

### Memory Management
```bash
# Monitoring m√©moire GPU en temps r√©el
watch -n 1 "nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits"

# Monitoring m√©moire container
docker stats agent-qlora-training
```

## Troubleshooting Training

### Erreurs GPU
```bash
# V√©rifier acc√®s GPU dans container
docker run --rm --gpus all nvidia/cuda:12.6.0-base-ubuntu22.04 nvidia-smi

# Logs d√©taill√©s CUDA
CUDA_LAUNCH_BLOCKING=1 make train-dev
```

### Out of Memory (OOM)
1. **R√©duire batch_size**: Modifier dans qlora_config.py
2. **Gradient checkpointing**: D√©j√† activ√© par d√©faut  
3. **Mod√®le plus petit**: Utiliser Gemma 2B au lieu de 9B
4. **4-bit quantization**: V√©rifier configuration QLoRA

### Slow Training
1. **GPU utilization**: V√©rifier >80% dans nvidia-smi
2. **DataLoader**: Augmenter num_workers si CPU disponible
3. **Mixed precision**: bf16 activ√© par d√©faut
4. **Storage I/O**: Placer volumes sur SSD NVMe

### Model Loading Issues  
```bash
# V√©rifier cache HuggingFace
ls -la models/.cache/huggingface/

# R√©initialiser cache si corrompu
rm -rf models/.cache/huggingface/
docker restart agent-qlora-training
```

## Migration et Int√©gration

### Vers Production
1. **Image optimis√©e**: Build avec stage training uniquement
2. **Secrets management**: Variables sensibles via Docker secrets
3. **Orchestration**: Kubernetes ou Docker Swarm pour scalabilit√©
4. **CI/CD**: Int√©gration avec pipeline MLOps automatis√©

### Int√©gration MLOps
- **Model Registry**: Int√©gration W&B/MLflow pour versioning
- **Automated Deployment**: Pipeline CI/CD avec tests mod√®les
- **Monitoring Production**: Drift detection et performance tracking
- **A/B Testing**: D√©ployment canary avec m√©triques business